# **Mini Project Two**

In this project, our group explored how we can visualize the places used in any news articles. Key techniques  were extracting place names from the text using **regex** and a **gazetteer**. We also applied **Named Entity Recognition (NER)** and **Geocoding** to visualize the places on a map. The Following is an oveerview of  main steps  to complete this project.

## Repository structure

We used a repository containing:

-A folder named "articles' with the news article corpus.
-A folder named "gazetteer" containing file named "geonames_gaza_selection", a tsv file containing a selection of places in gaza and a file named coordinates.tsv containing  a coordinate pair for each country in the world.

## Extracting Place names from articles (using Regex and gazetteer)

We made a script on python using a gazetteer to identify and tally place names mention across a large artcile corpus. It creates improved regx patterns for better detection
and aggregates mention counts by location and month, outputting results to a TSV file.
Following are the major steps taken to perform this task:

### Adapting the script

Firstly, I adapt the file path so that the script uses the gazetter and a larger corpus in our portfolio repository. Initially, the script only matched the main name(asciiname), but that missed a lot of mentions. So, I build a pattern to match the alternate names as well. For example,
** # extracting ascciname from column 1 **
    asciiname = columns[0]
   ** # Process the row if it has 6 or more columns**
    if asciiname:
        patterns[asciiname] = {"pattern": re.escape(asciiname), "count": 0}

   ** #extracting alternative names from 6th column**
    alternate_names = columns[5].strip()
    if alternate_names:
        alternate_list=alternate_names.split(",") **# Split by commas to handle multiple alternatives**
        for alternate in alternate_list:
            alternate=alternate.strip()
            if alternate:
                patterns[alternate]={"pattern":re.escape(alternate),"count":0} **# escaping speacial characters and adding alternate names if present**

Then, I adapt the script so that it skips the news artciles written before the start of current war (which i set as oct 7th, 2023).It does this by reading the data from each file name and skipping any file before that date. Afterwards, to ttrack how oftene each place is mentioned, i created a dictionary called mentions_per_month. It stores the number of mentions for each place in each month like this:

{
    'Gaza': {'2023-10': 12, '2023-11': 15},
    'Rafah': {'2023-11': 7}
}

### Writing ouputs

At the end, the scripts writes everything to a TSV file called reggex_count.tsv.This file has tnree columns: Placenames, counts and month. Each row tells how many times that place was mentioned.

### Keeping Track with Git

While working, I made sure to regularly add, commit, pull and push my changes with Git Bash:

git add .
git commit -m "message"
git pull origin main
git push origin main

### finalizing

once everything was done, I renamed my scipt to regex_script_final.py, this is the final version of  my script saved in the "scripts" Folder.


## NER with Stanza














## Building Gazetteer for the NER places



















## Mapping the regex extracted place names

This task visualizes the frequency per month of places extracted using regex.An animated and a static map is created with plotly express displays how often each place was mentioned over time.
Following are the major steps taken to perform this task:

### Data Preparation

- loaded geonames_gaza_selection.tsv containing  place names with their geographic coordinates (latitude and longitude).
- Loaded  regex_counts.tsv containing the frequency of mentions of those place names, extracted using regex, along with the corresponding month.
- Merged both datasets using the common column asciiname to combine geographic and frequency data into a single DataFrame. Note: **I adapted the python script for regex_counts to name the column with place names as asciiname, so that there will be no issue while merging the both files**.

### Visualization

- used plotly.express.scatter_geo() to create a world map showing place name frequencies.
- each dot represents a place; its size and color reflect how frequently it was mentioned.
- Added animation_frame="month" to visualize changes over time (one frame per month)
- customized the map appearance

### Design experiments

- Tried both scatter_geo and scatter_mapbox; chose scatter_geo because it worked well with the small geographic region (Gaza area) and required no additional API keys.
- Chose natural earth projection for a clean, minimalistic look that highlights data without clutter.

### Saving the output
- saved the map as: regex_map.html for web viewing and interaction, and as regex_map.png for a static snapshot of the full map.


## Mapping the NER extracted place names





